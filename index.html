<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Taeyoung Son</title> <meta name="author" content="Taeyoung Son"> <meta name="description" content="Taeyoung's personal webpage. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="taeyoung"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/vs.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%9D&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://taeyoungson.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/zenburn.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%74%79.%73%6F%6E@%70%6F%73%74%65%63%68.%61%63.%6B%72" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=s0gtpmIAAAAJ" title="Google Scholar" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/southflame" title="GitHub" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/namyupkim" title="LinkedIn" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-linkedin"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Taeyoung</span> Son </h1> <p class="desc">Research Scientist at <a href="https://www.nalbi.ai" rel="external nofollow noopener noopener noreferrer" target="_blank">NALBI</a></p> </header> <article> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_ty-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_ty-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_ty-1400.webp"></source> <img src="/assets/img/prof_ty.png" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_ty.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>I completed my Master‚Äôs Degree at <a href="https://cvlab.postech.ac.kr" rel="external nofollow noopener noopener noreferrer" target="_blank">Computer Vision Laboratory</a> at the <a href="https://cse.postech.ac.kr" rel="external nofollow noopener noopener noreferrer" target="_blank">Dept. of Computer Science and Engineering</a> of the <a href="https://postech.ac.kr" rel="external nofollow noopener noopener noreferrer" target="_blank">POSTECH</a>, advised by <a href="https://suhakwak.github.io" rel="external nofollow noopener noopener noreferrer" target="_blank">Prof. Suha Kwak</a>. I also did my BS at CSE of POSTECH.</p> <p>My interests include artifical intelligence, machine learning, computer vision, and software design and development. Research experiences contain domain adaptation and generalization, 3D human mesh reconstruction, image recognition under extreme condition(<em>e.g., rain, frost, snow and etc</em>). I am currently a research scientist at <a href="https://www.nalbi.ai" rel="external nofollow noopener noopener noreferrer" target="_blank">Nalbi</a>, mainly doing research and development over 3D human mesh reconstruction algorithm taking part in <em><a href="https://actionman.ai" rel="external nofollow noopener noopener noreferrer" target="_blank">Actionman</a></em></p> </div> <div class="news"> <h2>News</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Feb 1, 2023</th> <td> üìù A paper on domain generalization for semantic segmentation is accepted to ICRA 2023. </td> </tr> <tr> <th scope="row">Nov 7, 2022</th> <td> ü•≥ I won the Qualcomm Innovaation Fellowship 2022. </td> </tr> <tr> <th scope="row">Jun 11, 2022</th> <td> üìù A paper on foggy scene semantic segmentation is accepted to CVPR. </td> </tr> <tr> <th scope="row">Apr 4, 2022</th> <td> üè¢ I joined <a href="https://nalbi.ai" rel="external nofollow noopener noopener noreferrer" target="_blank">NALBI</a> as a research scientist. </td> </tr> <tr> <th scope="row">Nov 5, 2020</th> <td> üìù A paper on visual recognition under extreme condition is accepted to ECCV. </td> </tr> </table> </div> </div> <div class="education"> <h2>Education</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Mar, 2020 - Feb, 2022</th> <td> <a href="https://postech.ac.kr" rel="external nofollow noopener noopener noreferrer" target="_blank">Pohang University of Science and Technology (POSTECH)</a>, Pohang, South Korea <br> M.S. student in <a href="https://cse.postech.ac.kr" rel="external nofollow noopener noopener noreferrer" target="_blank">Computer Science and Engineering</a> <br> Advisor: <a href="https://suhakwak.github.io" rel="external nofollow noopener noopener noreferrer" target="_blank">Prof. Suha Kwak</a> </td> </tr> <tr> <th scope="row">Mar, 2015 - Feb, 2020</th> <td> <a href="https://postech.ac.kr" rel="external nofollow noopener noopener noreferrer" target="_blank">Pohang University of Science and Technology (POSTECH)</a>, Pohang, South Korea <br> B.S. in Computer Science and Engineering </td> </tr> </table> </div> </div> <div class="experience"> <h2>Experience</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">April, 2022 - Present</th> <td> <a href="https://nalbi.ai" rel="external nofollow noopener noopener noreferrer" target="_blank">NALBI</a>, Seoul, South Korea <br> <em>Research Scientist</em> <ul> <li>Led the design and implementation of a single-view 3D body mesh reconstruction algorithm, which deployed to Actionman.</li> <li>Led the design and implementation of automated SMPL annotation pipeline from a motion capture suit, for dataset creation.</li> <li>Leading the development of multi-view 3D body mesh reconstruction algorithm.</li> </ul> </td> </tr> <tr> <th scope="row">June, 2019 - Aug, 2019</th> <td> <a href="https://hyperconnect.com" rel="external nofollow noopener noopener noreferrer" target="_blank">Hyperconnect</a>, Seoul, South Korea <br> <em>Machine Learning Engineer</em> <ul> <li>Research Scientist Internship on self-supervised learning.</li> <li>Improved an algorithm to filter out specific type of an image from imbalanced dataset.</li> </ul> </td> </tr> <tr> <th scope="row">June, 2018 - Sep, 2018</th> <td> <a href="https://hyperconnect.com" rel="external nofollow noopener noopener noreferrer" target="_blank">Hyperconnect</a>, Seoul, South Korea <br> <em>Machine Learning Engineer</em> <ul> <li>Research Scientist Internship on image enhancement.</li> <li>Devised an algorithm (Neural Network) to generate image-to-image look-up-table for differentiable image beautification</li> </ul> </td> </tr> </table> </div> </div> <div class="publications"> <h2>Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/kim2021wedge-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/kim2021wedge-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/kim2021wedge-1400.webp"></source> <img src="/assets/img/publication_preview/kim2021wedge.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kim2021wedge" class="col-sm-8"> <div class="title">WEDGE: Web-Image Assisted Domain Generalization for Semantic Segmentation</div> <div class="author"> Namyup Kim,¬† <em>Taeyoung Son</em>,¬†Jaehyun Pahk,¬†Cuiling Lan,¬†Wenjun Zeng,¬† and Suha Kwak </div> <div class="periodical"> <em>IEEE International Conference on Robotics and Automation (<b>ICRA</b>),</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2109.14196" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener noopener noreferrer" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>Domain generalization for semantic segmentation is highly demanded in real applications, where a trained model is expected to work well in previously unseen domains. One challenge lies in the lack of data which could cover the diverse distributions of the possible unseen domains for training. In this paper, we propose a WEb-image assisted Domain GEneralization (WEDGE) scheme, which is the first to exploit the diversity of web-crawled images for generalizable semantic segmentation. To explore and exploit the real-world data distributions, we collect a web-crawled dataset which presents large diversity in terms of weather conditions, sites, lighting, camera styles, etc. We also present a method which injects the style representation of the web-crawled data into the source domain on-the-fly during training, which enables the network to experience images of diverse styles with reliable labels for effective training. Moreover, we use the web-crawled dataset with predicted pseudo labels for training to further enhance the capability of the network. Extensive experiments demonstrate that our method clearly outperforms existing domain generalization techniques.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/lee2022fifo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/lee2022fifo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/lee2022fifo-1400.webp"></source> <img src="/assets/img/publication_preview/lee2022fifo.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lee2022fifo" class="col-sm-8"> <div class="title">FIFO: Learning Fog-Invariant Features for Foggy Scene Segmentation</div> <div class="author"> Sohyun Lee,¬† <em>Taeyoung Son</em>,¬† and Suha Kwak </div> <div class="periodical"> <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2204.01587" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener noopener noreferrer" target="_blank">Paper</a> <a href="https://github.com/sohyun-l/fifo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener noopener noreferrer" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Robust visual recognition under adverse weather conditions is of great importance in real-world applications. In this context, we propose a new method for learning semantic segmentation models robust against fog. Its key idea is to consider the fog condition of an image as its style and close the gap between images with different fog conditions in neural style spaces of a segmentation model. In particular, since the neural style of an image is in general affected by other factors as well as fog, we introduce a fog-pass filter module that learns to extract a fog-relevant factor from the style. Optimizing the fog-pass filter and the segmentation model alternately gradually closes the style gap between different fog conditions and allows to learn fog-invariant features in consequence. Our method substantially outperforms previous work on three real foggy image datasets. Moreover, it improves performance on both foggy and clear weather images, while existing methods often degrade performance on clear scenes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/son2020urie-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/son2020urie-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/son2020urie-1400.webp"></source> <img src="/assets/img/publication_preview/son2020urie.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="son2020urie" class="col-sm-8"> <div class="title">Urie: Universal image enhancement for visual recognition in the wild</div> <div class="author"> <em>Taeyoung Son</em>,¬†Juwon Kang,¬†Namyup Kim,¬†Sunghyun Cho,¬† and Suha Kwak </div> <div class="periodical"> <em>European Conference on Computer Vision (<b>ECCV</b>),</em> 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2007.08979" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener noopener noreferrer" target="_blank">Paper</a> <a href="https://github.com/taeyoungson/urie" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener noopener noreferrer" target="_blank">Code</a> <a href="http://cvlab.postech.ac.kr/research/URIE/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener noopener noreferrer" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Despite the great advances in visual recognition, it has been witnessed that recognition models trained on clean images of common datasets are not robust against distorted images in the real world. To tackle this issue, we present a Universal and Recognition-friendly Image Enhancement network, dubbed URIE, which is attached in front of existing recognition models and enhances distorted input to improve their performance without retraining them. URIE is universal in that it aims to handle various factors of image degradation and to be incorporated with any arbitrary recognition models. Also, it is recognition-friendly since it is optimized to improve the robustness of following recognition models, instead of perceptual quality of output image. Our experiments demonstrate that URIE can handle various and latent image distortions and improve the performance of existing models for five diverse recognition tasks when input images are degraded.</p> </div> </div> </div> </li> </ol> </div> <div class="honors"> <h2>Honors and Awards</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <td> <strong>Qualcomm Innovation Fellowship South Korea (2022)</strong> <ul> <li>Winner ($3,000) - <em>FIFO: Learning fog-invariant features for foggy scene segmentation</em> (CVPR2022)</li> </ul> <strong>CVPR Best Paper Finalist (2022)</strong> <ul> <li>Our paper on foggy scene segmentation is nominated as a best paper finalist in CVPR 2022.</li> <li>Awarded to Top 0.4% (33 of 8161 papers)</li> <li><em>FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation</em></li> </ul> <strong>Seoul MaaS Hackerthon (2019)</strong> <ul> <li>Won excellence award at MaaS hackerthon hosted by the city of seoul</li> </ul> </td> </tr> </table> </div> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%74%79.%73%6F%6E@%70%6F%73%74%65%63%68.%61%63.%6B%72" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=s0gtpmIAAAAJ" title="Google Scholar" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/southflame" title="GitHub" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/namyupkim" title="LinkedIn" rel="external nofollow noopener noopener noreferrer" target="_blank"><i class="fab fa-linkedin"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2023 Taeyoung Son. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener noopener noreferrer" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>